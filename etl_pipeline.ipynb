{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from World Bank API\n",
    "def extract_world_bank_data(indicator, countries):\n",
    "    base_url = \"http://api.worldbank.org/v2/country/{}/indicator/{}?format=csv\"\n",
    "    country_codes = ';'.join(countries)\n",
    "    url = base_url.format(country_codes, indicator)\n",
    "    response = requests.get(url)\n",
    "    df = pd.read_csv(StringIO(response.text), skiprows=4)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from IMF API\n",
    "def extract_imf_data(dataset):\n",
    "    base_url = \"http://dataservices.imf.org/REST/SDMX_JSON.svc/CompactData/{}\"\n",
    "    url = base_url.format(dataset)\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    # Parse JSON data into a pandas DataFrame\n",
    "    # This is a simplified example and may need adjustment based on the actual IMF API response structure\n",
    "    df = pd.DataFrame(data['CompactData']['DataSet']['Series'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform and clean the data\n",
    "def transform_data(world_bank_df, imf_df):\n",
    "    # Merge datasets\n",
    "    merged_df = pd.merge(world_bank_df, imf_df, on=['Country', 'Year'], how='outer')\n",
    "    \n",
    "    # Clean data by removing rows with missing values\n",
    "    merged_df = merged_df.dropna()\n",
    "    \n",
    "    # Calculate additional metrics (e.g., Debt-to-GDP ratio)\n",
    "    merged_df['Debt_to_GDP_Ratio'] = merged_df['Government Debt'] / merged_df['GDP']\n",
    "    \n",
    "    # Normalize specific columns (GDP growth, Inflation, Unemployment)\n",
    "    columns_to_normalize = ['GDP growth', 'Inflation', 'Unemployment']\n",
    "    merged_df[columns_to_normalize] = (merged_df[columns_to_normalize] - merged_df[columns_to_normalize].mean()) / merged_df[columns_to_normalize].std()\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load transformed data into a database\n",
    "def load_data(df, database_url):\n",
    "    engine = create_engine(database_url)\n",
    "    table_name = 'economic_stability_data'\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL pipeline function\n",
    "def run_etl_pipeline():\n",
    "    # List of example countries\n",
    "    countries = ['USA', 'GBR', 'DEU', 'FRA', 'JPN', 'CHN', 'IND']\n",
    "    \n",
    "    # Extract data from World Bank (GDP growth) and IMF (Financial Soundness Indicators)\n",
    "    world_bank_df = extract_world_bank_data('NY.GDP.MKTP.KD.ZG', countries)\n",
    "    imf_df = extract_imf_data('FSI')\n",
    "    \n",
    "    # Transform the data\n",
    "    transformed_df = transform_data(world_bank_df, imf_df)\n",
    "    \n",
    "    # Load the data into a PostgreSQL database\n",
    "    database_url = 'postgresql://username:password@localhost:5432/economic_data'\n",
    "    load_data(transformed_df, database_url)\n",
    "    \n",
    "    print(f\"ETL pipeline completed at {datetime.now()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ETL pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl_pipeline()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
