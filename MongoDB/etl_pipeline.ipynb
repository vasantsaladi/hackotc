{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Country Name Code  1960      1961      1962      1963  \\\n",
      "0                        Aruba  ABW   NaN       NaN       NaN       NaN   \n",
      "1  Africa Eastern and Southern  AFE   NaN       NaN       NaN       NaN   \n",
      "2                  Afghanistan  AFG   NaN       NaN       NaN       NaN   \n",
      "3   Africa Western and Central  AFW   NaN  1.848719  3.770212  7.272501   \n",
      "4                       Angola  AGO   NaN       NaN       NaN       NaN   \n",
      "\n",
      "       1964      1965      1966      1967  ...       2012      2013      2014  \\\n",
      "0       NaN       NaN       NaN       NaN  ...  -1.369863  4.198232  0.300000   \n",
      "1       NaN       NaN       NaN       NaN  ...   1.972652  4.308370  3.986754   \n",
      "2       NaN       NaN       NaN       NaN  ...  12.752287  5.600745  2.724543   \n",
      "3  5.396356  4.049794 -1.787094 -9.546521  ...   5.142964  6.104241  5.927350   \n",
      "4       NaN       NaN       NaN       NaN  ...   8.542188  4.954545  4.822628   \n",
      "\n",
      "       2015      2016      2017      2018      2019      2020  Unnamed: 65  \n",
      "0  5.700001  2.100000  1.999999       NaN       NaN       NaN          NaN  \n",
      "1  2.925591  2.019391  2.542298  2.475272  2.077898 -2.939186          NaN  \n",
      "2  1.451315  2.260314  2.647003  1.189228  3.911603 -2.351101          NaN  \n",
      "3  2.745937  0.127595  2.318042  2.952230  3.190336 -0.884981          NaN  \n",
      "4  0.943572 -2.580050 -0.147213 -2.003630 -0.624644 -5.399987          NaN  \n",
      "\n",
      "[5 rows x 64 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 266 entries, 0 to 265\n",
      "Data columns (total 64 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country Name  266 non-null    object \n",
      " 1   Code          266 non-null    object \n",
      " 2   1960          0 non-null      float64\n",
      " 3   1961          119 non-null    float64\n",
      " 4   1962          124 non-null    float64\n",
      " 5   1963          124 non-null    float64\n",
      " 6   1964          124 non-null    float64\n",
      " 7   1965          124 non-null    float64\n",
      " 8   1966          132 non-null    float64\n",
      " 9   1967          136 non-null    float64\n",
      " 10  1968          138 non-null    float64\n",
      " 11  1969          142 non-null    float64\n",
      " 12  1970          139 non-null    float64\n",
      " 13  1971          153 non-null    float64\n",
      " 14  1972          153 non-null    float64\n",
      " 15  1973          153 non-null    float64\n",
      " 16  1974          153 non-null    float64\n",
      " 17  1975          155 non-null    float64\n",
      " 18  1976          159 non-null    float64\n",
      " 19  1977          161 non-null    float64\n",
      " 20  1978          167 non-null    float64\n",
      " 21  1979          167 non-null    float64\n",
      " 22  1980          168 non-null    float64\n",
      " 23  1981          183 non-null    float64\n",
      " 24  1982          188 non-null    float64\n",
      " 25  1983          191 non-null    float64\n",
      " 26  1984          191 non-null    float64\n",
      " 27  1985          194 non-null    float64\n",
      " 28  1986          195 non-null    float64\n",
      " 29  1987          199 non-null    float64\n",
      " 30  1988          202 non-null    float64\n",
      " 31  1989          204 non-null    float64\n",
      " 32  1990          207 non-null    float64\n",
      " 33  1991          217 non-null    float64\n",
      " 34  1992          218 non-null    float64\n",
      " 35  1993          221 non-null    float64\n",
      " 36  1994          222 non-null    float64\n",
      " 37  1995          224 non-null    float64\n",
      " 38  1996          234 non-null    float64\n",
      " 39  1997          234 non-null    float64\n",
      " 40  1998          237 non-null    float64\n",
      " 41  1999          238 non-null    float64\n",
      " 42  2000          239 non-null    float64\n",
      " 43  2001          244 non-null    float64\n",
      " 44  2002          245 non-null    float64\n",
      " 45  2003          250 non-null    float64\n",
      " 46  2004          250 non-null    float64\n",
      " 47  2005          251 non-null    float64\n",
      " 48  2006          251 non-null    float64\n",
      " 49  2007          252 non-null    float64\n",
      " 50  2008          251 non-null    float64\n",
      " 51  2009          253 non-null    float64\n",
      " 52  2010          253 non-null    float64\n",
      " 53  2011          253 non-null    float64\n",
      " 54  2012          253 non-null    float64\n",
      " 55  2013          253 non-null    float64\n",
      " 56  2014          255 non-null    float64\n",
      " 57  2015          254 non-null    float64\n",
      " 58  2016          254 non-null    float64\n",
      " 59  2017          254 non-null    float64\n",
      " 60  2018          253 non-null    float64\n",
      " 61  2019          251 non-null    float64\n",
      " 62  2020          244 non-null    float64\n",
      " 63  Unnamed: 65   0 non-null      float64\n",
      "dtypes: float64(62), object(2)\n",
      "memory usage: 133.1+ KB\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'error_bad_lines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Read the CSV file and create a DataFrame\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     world_bank_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bad_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn_bad_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV file read successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pd\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mParserError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'error_bad_lines'"
     ]
    }
   ],
   "source": [
    "# Define the correct path to the CSV file\n",
    "csv_path = 'data/gdp_growth.csv'\n",
    "\n",
    "# Check if the file exis\n",
    "# Read the CSV file and create a DataFrame\n",
    "world_bank_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(world_bank_df.head())\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(world_bank_df.info())\n",
    "\n",
    "# Read the CSV file and create a DataFrame\n",
    "try:\n",
    "    world_bank_df = pd.read_csv(csv_path, sep='\\t', error_bad_lines=False, warn_bad_lines=True)\n",
    "    print(\"CSV file read successfully.\")\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error reading CSV file: {e}\")\n",
    "    print(\"Attempting to read with different settings...\")\n",
    "    try:\n",
    "        world_bank_df = pd.read_csv(csv_path, sep=',', encoding='utf-8', quotechar='\"', error_bad_lines=False, warn_bad_lines=True)\n",
    "        print(\"CSV file read successfully with alternative settings.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read CSV file: {e}\")\n",
    "        world_bank_df = pd.DataFrame()  # Create an empty DataFrame if all attempts fail\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "if not world_bank_df.empty:\n",
    "    print(world_bank_df.head())\n",
    "    # Display basic information about the DataFrame\n",
    "    print(world_bank_df.info())\n",
    "else:\n",
    "    print(\"DataFrame is empty. Please check the CSV file and its path.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from IMF API\n",
    "def extract_imf_data(dataset):\n",
    "    base_url = \"http://dataservices.imf.org/REST/SDMX_JSON.svc/CompactData/{}\"\n",
    "    url = base_url.format(dataset)\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    # Parse JSON data into a pandas DataFrame\n",
    "    # This is a simplified example and may need adjustment based on the actual IMF API response structure\n",
    "    df = pd.DataFrame(data['CompactData']['DataSet']['Series'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform and clean the data\n",
    "def transform_data(world_bank_df, imf_df):\n",
    "    # Merge datasets\n",
    "    merged_df = pd.merge(world_bank_df, imf_df, on=['Country', 'Year'], how='outer')\n",
    "    \n",
    "    # Clean data by removing rows with missing values\n",
    "    merged_df = merged_df.dropna()\n",
    "    \n",
    "    # Calculate additional metrics (e.g., Debt-to-GDP ratio)\n",
    "    merged_df['Debt_to_GDP_Ratio'] = merged_df['Government Debt'] / merged_df['GDP']\n",
    "    \n",
    "    # Normalize specific columns (GDP growth, Inflation, Unemployment)\n",
    "    columns_to_normalize = ['GDP growth', 'Inflation', 'Unemployment']\n",
    "    merged_df[columns_to_normalize] = (merged_df[columns_to_normalize] - merged_df[columns_to_normalize].mean()) / merged_df[columns_to_normalize].std()\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load transformed data into a database\n",
    "def load_data(df, database_url):\n",
    "    engine = create_engine(database_url)\n",
    "    table_name = 'economic_stability_data'\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL pipeline function\n",
    "def run_etl_pipeline():\n",
    "    # List of example countries\n",
    "    countries = ['USA', 'GBR', 'DEU', 'FRA', 'JPN', 'CHN', 'IND']\n",
    "    \n",
    "    # Extract data from World Bank (GDP growth) and IMF (Financial Soundness Indicators)\n",
    "    world_bank_df = extract_world_bank_data('NY.GDP.MKTP.KD.ZG', countries)\n",
    "    imf_df = extract_imf_data('FSI')\n",
    "    \n",
    "    # Transform the data\n",
    "    transformed_df = transform_data(world_bank_df, imf_df)\n",
    "    \n",
    "    # Load the data into a PostgreSQL database\n",
    "    database_url = 'postgresql://username:password@localhost:5432/economic_data'\n",
    "    load_data(transformed_df, database_url)\n",
    "    \n",
    "    print(f\"ETL pipeline completed at {datetime.now()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ETL pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
